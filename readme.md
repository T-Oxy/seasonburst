- _result_01は無視

- ファイルの入力・出力先は適宜変更してください。

### 基本手順

まずは、main_scriptディレクトリ内のプログラムを実行して、推定に必要な諸々のツイート数をカウントします。
結果は、resultディレクトリ内に保存されます。

結構時間が掛かるので、screenコマンドでssh接続が途絶えてもいいようにしておくといいと思います。

- 00count_tweets.py
  - ツイートの総数を日次でカウントするプログラム

- 01get_related_words4_count.py
  - **2014年**のツイートデータから関連キーワードリストを作成するプログラム
  - pmi順とsoa順を両方出力しますが、使っているのはsoa順のみです。
  - 30min ~ 1hくらい

- 02count_rtweets.py
  - **2015年**のツイートデータから関連ツイートの数を日次でカウントするプログラム
  - 上で作った関連キーワードリストを用いて日次にカウントします。
  - 共起語すべてを使うのではなく、関連度(soa)の高い上位1割を使った場合の日次ツイート数、上位2割の場合... という様に使う関連キーワード数を変えた場合の関連ツイート数をそれぞれ出力します。



次にresultディレクトリをローカル環境に持ってきて、以下のプログラムで見頃推定を行います。
プログラムはJupyter labかjupyter notebookで動かします。

- detect.ipynb
  - 見頃推定を行うプログラムです。
  - 作成されるディレクトリ
    - burst_dates/
      - hk_icho_10.csv → 北海道のイチョウをsoa上位10%の関連キーワードを用いて見頃推定した結果
      - 0が非見頃、1が見頃
    - graph/
      - s1.5gamma1.0 → sとgammaはバースト検出アルゴリズム内で用いているパラメーター。1.5と1.0は推定に用いたパラメーター値（デフォルト）。
      - 推定結果をプロットしたものが県ごとのディレクトリに入っています。
    - scores/
      - accurency, recall, precisionの値が入っています
- plot_fcores.ipynb
  - 上で作成したaccurency, recall, precisionのcsvを用いてF値のグラフをプロットするプログラム
  - 条件の違う推定結果の比較をプロットする際に使っていました。
  - あまり手を入れていないので汚い。